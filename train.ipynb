{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Divide data into train and test folders"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-02-23T06:57:00.02483Z","iopub.status.busy":"2022-02-23T06:57:00.023775Z","iopub.status.idle":"2022-02-23T06:58:53.551561Z","shell.execute_reply":"2022-02-23T06:58:53.550754Z","shell.execute_reply.started":"2022-02-23T06:57:00.024699Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np \n","import shutil\n","import os\n","\n","rootdir = '/kaggle/input/plantdisease/PlantVillage'\n","destroot = '/kaggle/working'\n","classes = [x[0].split('/')[-1] for x in os.walk(rootdir)][1:]\n","for i in classes:\n","    if not os.path.exists(destroot +'/divided/train/' + i):\n","        os.makedirs(destroot +'/divided/train/' + i)\n","    if not os.path.exists(destroot +'/divided/test/' + i):\n","        os.makedirs(destroot +'/divided/test/' + i)\n","    source = rootdir + '/' + i\n","    allFileNames = os.listdir(source)\n","    np.random.shuffle(allFileNames)\n","    test_ratio = 0.25\n","    train_FileNames, test_FileNames = np.split(np.array(allFileNames), \\\n","    [int(len(allFileNames)* (1 - test_ratio))])\n","    train_FileNames = [source+'/'+ name for name in train_FileNames.tolist()]\n","    test_FileNames = [source+'/' + name for name in test_FileNames.tolist()]\n","\n","    for name in train_FileNames:\n","      shutil.copy(name, destroot +'/divided/train/' + i)\n","\n","    for name in test_FileNames:\n","      shutil.copy(name, destroot +'/divided/test/' + i)\n","\n","# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T07:09:27.043129Z","iopub.status.busy":"2022-02-23T07:09:27.042869Z","iopub.status.idle":"2022-02-23T07:09:27.050317Z","shell.execute_reply":"2022-02-23T07:09:27.049561Z","shell.execute_reply.started":"2022-02-23T07:09:27.0431Z"},"trusted":true},"outputs":[],"source":["# re-size all the images to this\n","IMAGE_SIZE = [224, 224]\n","train_path = '/kaggle/working/divided/train'\n","valid_path = '/kaggle/working/divided/test'\n","weight_path = '../input/keraspretrainedmodel/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","def return_string(predicted_class, classes):\n","    predicted = sorted(classes)[predicted_class]\n","    return 'This is '+ predicted + '!'\n","    \n","   \n"]},{"cell_type":"markdown","metadata":{},"source":["##  train InceptionResNetV2 model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-22T14:21:49.489034Z","iopub.status.busy":"2022-02-22T14:21:49.488771Z","iopub.status.idle":"2022-02-22T16:27:18.331036Z","shell.execute_reply":"2022-02-22T16:27:18.330123Z","shell.execute_reply.started":"2022-02-22T14:21:49.489005Z"},"trusted":true},"outputs":[],"source":["from tensorflow._api.v2.compat.v1 import ConfigProto\n","from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dense, Flatten, MaxPooling2D\n","from keras.models import Model, Sequential, load_model\n","from keras.applications.inception_resnet_v2  import InceptionResNetV2, preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# from utils import *\n","import os\n","# Import the InceptionV3  \n","# USE imagenet weights for Transfer Learning\n","IMAGE_SIZE = [299, 299]\n","weight_path3 = '../input/keraspretrainedmodel/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","resnet = InceptionResNetV2(input_shape=IMAGE_SIZE + [3],weights = weight_path3,input_tensor=None, include_top=False)\n","# we don't train existing weights. \n","# We only train the last layer that will predict the predicted_classes\n","for layer in resnet.layers:\n","    layer.trainable = False\n","x =resnet.output\n","x = Flatten()(x)\n","prediction = Dense(15, activation='softmax')(x)\n","\n","# create a model object\n","model = Model(inputs=resnet.input, outputs=prediction)\n","# Specify which cost func and optimization method to use\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")\n","\n","# Use the Image Data Generator to process images (data aug) on the fly\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#Specify the new size of the images and batch size\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 interpolation=\"bicubic\",\n","                                                 target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","test_set = test_datagen.flow_from_directory(valid_path,\n","                                            interpolation=\"bicubic\",\n","                                            target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')\n","\n","#set up the callback to save best model's weights\n","checkpoint_filepath = 'InceptionResNetV2.h5'\n","es_callback = EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","\n","try:\n","    r = model.fit_generator(\n","      training_set,\n","      validation_data=test_set,\n","      epochs=50,\n","      steps_per_epoch=len(training_set),\n","      validation_steps=len(test_set), \n","      callbacks=[model_checkpoint_callback, es_callback]\n","    )\n","except KeyboardInterrupt:\n","    model.save(checkpoint_filepath)\n","\n","# plot the loss\n","plt.plot(r.history['loss'], label='train loss')\n","plt.plot(r.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.savefig('./train_val_loss_InceptionResNetV2.jpg')\n","plt.show()\n","\n","# plot the accuracy\n","plt.plot(r.history['accuracy'], label='train acc')\n","plt.plot(r.history['val_accuracy'], label='val acc')\n","plt.legend()\n","#save before show\n","plt.savefig('./train_val_acc_InceptionResNetV2.jpg')\n","plt.show()\n","model.save(checkpoint_filepath)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Set up a cycling Schedule for Learning Rate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T10:13:57.031348Z","iopub.status.busy":"2022-02-23T10:13:57.031102Z","iopub.status.idle":"2022-02-23T10:13:57.053154Z","shell.execute_reply":"2022-02-23T10:13:57.052383Z","shell.execute_reply.started":"2022-02-23T10:13:57.031319Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, Callback\n","from keras import backend as K\n","\n","class CyclicLR(Callback):\n","    def __init__(\n","            self,base_lr=0.001,\n","            max_lr=0.006,step_size=2000.,\n","            mode='triangular',gamma=1.,\n","            scale_fn=None,scale_mode='cycle'):\n","        \n","        super(CyclicLR, self).__init__()\n","\n","        if mode not in ['triangular', 'triangular2','exp_range']:\n","            raise KeyError(\"mode must be one of 'triangular', \"\n","                           \"'triangular2', or 'exp_range'\")\n","        self.base_lr = base_lr\n","        self.max_lr = max_lr\n","        self.step_size = step_size\n","        self.mode = mode\n","        self.gamma = gamma\n","        if scale_fn is None:\n","            if self.mode == 'triangular':\n","                self.scale_fn = lambda x: 1.\n","                self.scale_mode = 'cycle'\n","            elif self.mode == 'triangular2':\n","                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n","                self.scale_mode = 'cycle'\n","            elif self.mode == 'exp_range':\n","                self.scale_fn = lambda x: gamma ** x\n","                self.scale_mode = 'iterations'\n","        else:\n","            self.scale_fn = scale_fn\n","            self.scale_mode = scale_mode\n","        self.clr_iterations = 0.\n","        self.trn_iterations = 0.\n","        self.history = {}\n","\n","        self._reset()\n","\n","    def _reset(self, new_base_lr=None, new_max_lr=None,\n","               new_step_size=None):\n","        if new_base_lr is not None:\n","            self.base_lr = new_base_lr\n","        if new_max_lr is not None:\n","            self.max_lr = new_max_lr\n","        if new_step_size is not None:\n","            self.step_size = new_step_size\n","        self.clr_iterations = 0.\n","        \n","    def clr(self):\n","        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n","        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n","        if self.scale_mode == 'cycle':\n","            return self.base_lr + (self.max_lr - self.base_lr) * \\\n","                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n","        else:\n","            return self.base_lr + (self.max_lr - self.base_lr) * \\\n","                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n","\n","    def on_train_begin(self, logs={}):\n","        logs = logs or {}\n","\n","        if self.clr_iterations == 0:\n","            K.set_value(self.model.optimizer.lr, self.base_lr)\n","        else:\n","            K.set_value(self.model.optimizer.lr, self.clr())\n","\n","    def on_batch_end(self, epoch, logs=None):\n","\n","        logs = logs or {}\n","        self.trn_iterations += 1\n","        self.clr_iterations += 1\n","        K.set_value(self.model.optimizer.lr, self.clr())\n","\n","        self.history.setdefault(\n","            'lr', []).append(\n","            K.get_value(\n","                self.model.optimizer.lr))\n","        self.history.setdefault('iterations', []).append(self.trn_iterations)\n","\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        logs['lr'] = K.get_value(self.model.optimizer.lr)\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train InceptionResNetV2 Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T07:09:47.743228Z","iopub.status.busy":"2022-02-23T07:09:47.742881Z","iopub.status.idle":"2022-02-23T08:13:33.27934Z","shell.execute_reply":"2022-02-23T08:13:33.27843Z","shell.execute_reply.started":"2022-02-23T07:09:47.743193Z"},"trusted":true},"outputs":[],"source":["from tensorflow._api.v2.compat.v1 import ConfigProto\n","from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dense, Flatten, MaxPooling2D\n","from keras.models import Model, Sequential, load_model\n","from keras.applications.inception_resnet_v2  import InceptionResNetV2, preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# from utils import *\n","import os\n","# USE imagenet weights for Transfer Learning\n","IMAGE_SIZE = [256, 256]\n","weight_path3 = '../input/keraspretrainedmodel/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","resnet = InceptionResNetV2(input_shape=IMAGE_SIZE + [3],weights = weight_path3,input_tensor=None, include_top=False)\n","# we don't train existing weights. \n","# We only train the last layer that will predict the predicted_classes\n","for layer in resnet.layers:\n","    layer.trainable = False\n","x =resnet.output\n","x = Flatten()(x)\n","prediction = Dense(15, activation='softmax')(x)\n","\n","# create a model object\n","model = Model(inputs=resnet.input, outputs=prediction)\n","# Specify which cost func and optimization method to use\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")\n","\n","# Use the Image Data Generator to process images (data aug) on the fly\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#Specify the new size of the images and batch size\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 interpolation=\"bicubic\",\n","                                                 target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","test_set = test_datagen.flow_from_directory(valid_path,\n","                                            interpolation=\"bicubic\",\n","                                            target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')\n","\n","#set up the callback to save best model's weights\n","checkpoint_filepath = 'InceptionResNetV2_clr.h5'\n","es_callback = EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n","\n","clr = CyclicLR(base_lr=0.0006, max_lr=0.001,step_size=25, mode='triangular')\n","\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","\n","try:\n","    r = model.fit_generator(\n","      training_set,\n","      validation_data=test_set,\n","      epochs=50,\n","      steps_per_epoch=len(training_set),\n","      validation_steps=len(test_set), \n","      callbacks=[model_checkpoint_callback, clr]\n","    )\n","except KeyboardInterrupt:\n","    model.save(checkpoint_filepath)\n","\n","# plot the loss\n","plt.plot(r.history['loss'], label='train loss')\n","plt.plot(r.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.savefig('./train_val_loss_InceptionResNetV2_lr.jpg')\n","plt.show()\n","\n","# plot the accuracy\n","plt.plot(r.history['accuracy'], label='train acc')\n","plt.plot(r.history['val_accuracy'], label='val acc')\n","plt.legend()\n","#save before show\n","plt.savefig('./train_val_acc_InceptionResNetV2_lr.jpg')\n","plt.show()\n","model.save(checkpoint_filepath)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Define Resnet9 from scratch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T12:59:27.737219Z","iopub.status.busy":"2022-02-23T12:59:27.736946Z","iopub.status.idle":"2022-02-23T12:59:27.750213Z","shell.execute_reply":"2022-02-23T12:59:27.749513Z","shell.execute_reply.started":"2022-02-23T12:59:27.73719Z"},"trusted":true},"outputs":[],"source":["from keras.layers import ReLU,Concatenate, Dense, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, MaxPooling2D\n","from keras import Sequential, activations, Input\n","from keras.models import Model\n","\n","\n","# convolution block with BatchNormalization\n","def ConvBlock(out_channels, pool=False):\n","    layers = [Conv2D(filters = out_channels, kernel_size=(3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4)),\n","             BatchNormalization(axis=3,epsilon=1e-05, momentum=0.1),\n","             ReLU()]\n","    if pool:\n","        layers.append(MaxPooling2D(pool_size=(2, 2), strides=4, padding='valid'))\n","          \n","    return Sequential(layers)\n","\n","# resnet architecture \n","def ResNet9(nb_classes,IMG_SIZE):\n","    input_tensor = Input(shape=(IMG_SIZE[0], IMG_SIZE[1],3))   \n","    conv1 = ConvBlock(64)\n","    conv2 = ConvBlock(128, pool=True) # out_dim : 128 x 64 x 64 \n","    res1 = Sequential([ConvBlock(128), ConvBlock(128)])\n","    conv3 = ConvBlock(256, pool=True) # out_dim : 256 x 16 x 16\n","    conv4 = ConvBlock(512, pool=True) # out_dim : 512 x 4 x 44\n","    res2 = Sequential([ConvBlock(512), ConvBlock(512)])\n","    classifier = Sequential([MaxPooling2D(pool_size=(4, 4), strides=4, padding='valid'),\n","                                   Flatten(),\n","                                   Dense(nb_classes, activation='softmax')])\n","    x = input_tensor\n","    x = conv1(x)\n","    x = conv2(x)\n","    x = Concatenate(axis=1)([res1(x), x])\n","    x = conv3(x)\n","    x = conv4(x)\n","    x = Concatenate(axis=1)([res2(x) , x])\n","    classifier = classifier(x)\n","    model = Model(inputs=input_tensor, outputs=classifier)\n","    return model   "]},{"cell_type":"markdown","metadata":{},"source":["## Train Resnet9: This is our best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T10:21:01.218892Z","iopub.status.busy":"2022-02-23T10:21:01.218622Z","iopub.status.idle":"2022-02-23T12:29:57.070657Z","shell.execute_reply":"2022-02-23T12:29:57.06989Z","shell.execute_reply.started":"2022-02-23T10:21:01.21886Z"},"trusted":true},"outputs":[],"source":["from tensorflow._api.v2.compat.v1 import ConfigProto\n","from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dense, Flatten, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam # - Works\n","\n","from keras.models import Model, Sequential, load_model\n","# from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# from utils import *\n","import os\n","# Import the InceptionV3  \n","# USE imagenet weights for Transfer Learning\n","IMAGE_SIZE = [256, 256]\n","\n","model = ResNet9(15,IMAGE_SIZE)\n","\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='SGD',\n","  metrics=['accuracy']\n",")\n","\n","# Use the Image Data Generator to process images (data aug) on the fly\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#Specify the new size of the images and batch size\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                                 batch_size = 16,\n","                                                 class_mode = 'categorical')\n","test_set = test_datagen.flow_from_directory(valid_path,\n","                                            target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                            batch_size = 16,\n","                                            class_mode = 'categorical')\n","\n","#set up the callback to save best model's weights\n","checkpoint_filepath = 'inception_resnet9.h5'\n","es_callback = EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n","clr = CyclicLR(base_lr=0.0006, max_lr=0.01,step_size=25, mode='triangular')\n","\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","# fit the model\n","# load the model\n","# if os.path.exists(checkpoint_filepath):\n","#   model = load_model(checkpoint_filepath)\n","try:\n","    r = model.fit_generator(\n","      training_set,\n","      validation_data=test_set,\n","      epochs=30,\n","      steps_per_epoch=len(training_set),\n","      validation_steps=len(test_set), \n","      callbacks=[model_checkpoint_callback, es_callback,clr]\n","    )\n","except:\n","    model.save(checkpoint_filepath)\n","# plot the loss\n","plt.plot(clr.history['loss'], label='train loss')\n","plt.plot(clr.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.savefig('./train_val_loss_resnet9.jpg')\n","plt.show()\n","\n","\n","# plot the accuracy\n","plt.plot(clr.history['accuracy'], label='train acc')\n","plt.plot(clr.history['val_accuracy'], label='val acc')\n","plt.legend()\n","#save before show\n","plt.savefig('./train_val_acc_resnet9.jpg')\n","plt.show()\n","\n","model.save(checkpoint_filepath)\n","#See predictions: For each image, we get probabilities for every predicted_class\n","# y_pred = model.predict(test_set)\n","# #we need to choose the predicted_class with the highest prob\n","# y_pred = np.argmax(y_pred, axis=1)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training Resnet9 using Clipping values: ended up not giving better results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T14:18:27.244883Z","iopub.status.busy":"2022-02-23T14:18:27.244536Z"},"trusted":true},"outputs":[],"source":["from tensorflow._api.v2.compat.v1 import ConfigProto\n","from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dense, Flatten, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam # - Works\n","from keras.models import Model, Sequential, load_model\n","# from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.regularizers import l2\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# from utils import *\n","import os\n","# Import the InceptionV3  \n","# USE imagenet weights for Transfer Learning\n","IMAGE_SIZE = [256, 256]\n","model = ResNet9(15,IMAGE_SIZE)\n","\n","clipvalue=0.1\n","optim = Adam(clipvalue=clipvalue)\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer=optim,\n","  metrics=['accuracy']\n",")\n","\n","# Use the Image Data Generator to process images (data aug) on the fly\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#Specify the new size of the images and batch size\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","test_set = test_datagen.flow_from_directory(valid_path,\n","                                            target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')\n","\n","#set up the callback to save best model's weights\n","checkpoint_filepath = 'inception_resnet9_wd.h5'\n","es_callback = EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n","# clr = CyclicLR(base_lr=0.0006, max_lr=0.01,step_size=15, mode='triangular')\n","\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","# fit the model\n","# load the model\n","# if os.path.exists(checkpoint_filepath):\n","#   model = load_model(checkpoint_filepath)\n","try:\n","    r = model.fit_generator(\n","      training_set,\n","      validation_data=test_set,\n","      epochs=40,\n","      steps_per_epoch=len(training_set),\n","      validation_steps=len(test_set), \n","      callbacks=[model_checkpoint_callback, es_callback,clr]\n","    )\n","except:\n","    model.save(checkpoint_filepath)\n","# plot the loss\n","plt.plot(clr.history['loss'], label='train loss')\n","plt.plot(clr.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.savefig('./train_val_loss_resnet9_wd.jpg')\n","plt.show()\n","\n","\n","# plot the accuracy\n","plt.plot(clr.history['accuracy'], label='train acc')\n","plt.plot(clr.history['val_accuracy'], label='val acc')\n","plt.legend()\n","#save before show\n","plt.savefig('./train_val_acc_resnet9_wd.jpg')\n","plt.show()\n","\n","model.save(checkpoint_filepath)\n","#See predictions: For each image, we get probabilities for every predicted_class\n","# y_pred = model.predict(test_set)\n","# #we need to choose the predicted_class with the highest prob\n","# y_pred = np.argmax(y_pred, axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, Callback\n","from keras import backend as K\n","\n","class CyclicLR(Callback):\n","    def __init__(\n","            self,base_lr=0.001,\n","            max_lr=0.006,step_size=2000.,\n","            mode='triangular',gamma=1.,\n","            scale_fn=None,scale_mode='cycle'):\n","        \n","        super(CyclicLR, self).__init__()\n","\n","        if mode not in ['triangular', 'triangular2','exp_range']:\n","            raise KeyError(\"mode must be one of 'triangular', \"\n","                           \"'triangular2', or 'exp_range'\")\n","        self.base_lr = base_lr\n","        self.max_lr = max_lr\n","        self.step_size = step_size\n","        self.mode = mode\n","        self.gamma = gamma\n","        if scale_fn is None:\n","            if self.mode == 'triangular':\n","                self.scale_fn = lambda x: 1.\n","                self.scale_mode = 'cycle'\n","            elif self.mode == 'triangular2':\n","                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n","                self.scale_mode = 'cycle'\n","            elif self.mode == 'exp_range':\n","                self.scale_fn = lambda x: gamma ** x\n","                self.scale_mode = 'iterations'\n","        else:\n","            self.scale_fn = scale_fn\n","            self.scale_mode = scale_mode\n","        self.clr_iterations = 0.\n","        self.trn_iterations = 0.\n","        self.history = {}\n","\n","        self._reset()\n","\n","    def _reset(self, new_base_lr=None, new_max_lr=None,\n","               new_step_size=None):\n","        if new_base_lr is not None:\n","            self.base_lr = new_base_lr\n","        if new_max_lr is not None:\n","            self.max_lr = new_max_lr\n","        if new_step_size is not None:\n","            self.step_size = new_step_size\n","        self.clr_iterations = 0.\n","        \n","    def clr(self):\n","        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n","        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n","        if self.scale_mode == 'cycle':\n","            return self.base_lr + (self.max_lr - self.base_lr) * \\\n","                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n","        else:\n","            return self.base_lr + (self.max_lr - self.base_lr) * \\\n","                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n","\n","    def on_train_begin(self, logs={}):\n","        logs = logs or {}\n","\n","        if self.clr_iterations == 0:\n","            K.set_value(self.model.optimizer.lr, self.base_lr)\n","        else:\n","            K.set_value(self.model.optimizer.lr, self.clr())\n","\n","    def on_batch_end(self, epoch, logs=None):\n","\n","        logs = logs or {}\n","        self.trn_iterations += 1\n","        self.clr_iterations += 1\n","        K.set_value(self.model.optimizer.lr, self.clr())\n","        \n","        self.history.setdefault(\n","            'lr', []).append(\n","            K.get_value(\n","                self.model.optimizer.lr))\n","        self.history.setdefault('iterations', []).append(self.trn_iterations)\n","\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        #logs['lr'] = K.get_value(self.model.optimizer.lr)\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","        self.history.setdefault('epochs', []).append(epoch)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training InceptionV3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-22T12:08:28.827727Z","iopub.status.busy":"2022-02-22T12:08:28.827321Z","iopub.status.idle":"2022-02-22T13:16:29.534622Z","shell.execute_reply":"2022-02-22T13:16:29.533467Z","shell.execute_reply.started":"2022-02-22T12:08:28.827694Z"},"trusted":true},"outputs":[],"source":["from tensorflow._api.v2.compat.v1 import ConfigProto\n","from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dense, Flatten, MaxPooling2D\n","from keras.models import Model, Sequential, load_model\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# from utils import *\n","import os\n","# Import the InceptionV3  \n","# USE imagenet weights for Transfer Learning\n","IMAGE_SIZE = [256, 256]\n","\n","inception = InceptionV3(input_shape=IMAGE_SIZE + [3],weights = weight_path, include_top=False)\n","# we don't train existing weights. \n","# We only train the last layer that will predict the predicted_classes\n","for layer in inception.layers:\n","    layer.trainable = False\n","\n","# Add preprocessing layer to the head of InceptionV3\n","#We use softmax because we have 15 predicted_classes\n","x = MaxPooling2D()(inception.output)\n","x = Flatten()(x)\n","x = Dense(1024, activation='relu')(x)\n","x = Dense(612, activation='relu')(x)\n","prediction = Dense(15, activation='softmax')(x)\n","\n","# create a model object\n","model = Model(inputs=inception.input, outputs=prediction)\n","# Specify which cost func and optimization method to use\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")\n","\n","# Use the Image Data Generator to process images (data aug) on the fly\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#Specify the new size of the images and batch size\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                                 batch_size = 16,\n","                                                 class_mode = 'categorical')\n","test_set = test_datagen.flow_from_directory(valid_path,\n","                                            target_size = (IMAGE_SIZE[0],IMAGE_SIZE[0]),\n","                                            batch_size = 16,\n","                                            class_mode = 'categorical')\n","\n","#set up the callback to save best model's weights\n","checkpoint_filepath = 'inception_128_More_Dense.h5'\n","es_callback = EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","# fit the model\n","# load the model\n","# if os.path.exists(checkpoint_filepath):\n","#   model = load_model(checkpoint_filepath)\n","r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=50,\n","  steps_per_epoch=len(training_set),\n","  validation_steps=len(test_set), \n","  callbacks=[model_checkpoint_callback, es_callback]\n",")\n","\n","# plot the loss\n","plt.plot(r.history['loss'], label='train loss')\n","plt.plot(r.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.savefig('./train_val_loss_128_More_Dense.jpg')\n","plt.show()\n","\n","\n","# plot the accuracy\n","plt.plot(r.history['accuracy'], label='train acc')\n","plt.plot(r.history['val_accuracy'], label='val acc')\n","plt.legend()\n","#save before show\n","plt.savefig('./train_val_acc_128_More_Dense.jpg')\n","plt.show()\n","\n","\n","#load best weights\n","# The model weights (that are considered the best) are loaded into the model.\n","#model.load_weights(checkpoint_filepath)\n","model.save(checkpoint_filepath)\n","#See predictions: For each image, we get probabilities for every predicted_class\n","# y_pred = model.predict(test_set)\n","# #we need to choose the predicted_class with the highest prob\n","# y_pred = np.argmax(y_pred, axis=1)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Downloading best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-23T13:59:05.300131Z","iopub.status.busy":"2022-02-23T13:59:05.299581Z","iopub.status.idle":"2022-02-23T13:59:05.305199Z","shell.execute_reply":"2022-02-23T13:59:05.304542Z","shell.execute_reply.started":"2022-02-23T13:59:05.300095Z"},"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(r'./resnet9.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## Training InceptionV3 with different IMAGE SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-22T08:12:47.324201Z","iopub.status.busy":"2022-02-22T08:12:47.323745Z","iopub.status.idle":"2022-02-22T08:55:17.954699Z","shell.execute_reply":"2022-02-22T08:55:17.950166Z","shell.execute_reply.started":"2022-02-22T08:12:47.324157Z"},"trusted":true},"outputs":[],"source":["from tensorflow._api.v2.compat.v1 import ConfigProto\n","from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Dense, Flatten\n","from keras.models import Model, Sequential, load_model\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# from utils import *\n","import os\n","# Import the InceptionV3  \n","# USE imagenet weights for Transfer Learning\n","IMAGE_SIZE = [128, 128]\n","\n","inception = InceptionV3(input_shape=IMAGE_SIZE + [3],weights = weight_path, include_top=False)\n","# we don't train existing weights. \n","# We only train the last layer that will predict the predicted_classes\n","for layer in inception.layers:\n","    layer.trainable = False\n","\n","# Add preprocessing layer to the head of InceptionV3\n","#We use softmax because we have 15 predicted_classes\n","x = Flatten()(inception.output)\n","prediction = Dense(15, activation='softmax')(x)\n","\n","# create a model object\n","model = Model(inputs=inception.input, outputs=prediction)\n","# Specify which cost func and optimization method to use\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")\n","\n","# Use the Image Data Generator to process images (data aug) on the fly\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#Specify the new size of the images and batch size\n","training_set = train_datagen.flow_from_directory(train_path,\n","                                                 target_size = (128,128),\n","                                                 batch_size = 64,\n","                                                 class_mode = 'categorical')\n","test_set = test_datagen.flow_from_directory(valid_path,\n","                                            target_size = (128,128),\n","                                            batch_size = 64,\n","                                            class_mode = 'categorical')\n","\n","#set up the callback to save best model's weights\n","checkpoint_filepath = 'inception_128.h5'\n","es_callback = EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=False,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)\n","# fit the model\n","# load the model\n","# if os.path.exists(checkpoint_filepath):\n","#   model = load_model(checkpoint_filepath)\n","r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=50,\n","  steps_per_epoch=len(training_set),\n","  validation_steps=len(test_set), \n","  callbacks=[model_checkpoint_callback, es_callback]\n",")\n","\n","# plot the loss\n","plt.plot(r.history['loss'], label='train loss')\n","plt.plot(r.history['val_loss'], label='val loss')\n","plt.legend()\n","plt.savefig('./train_val_loss_128.jpg')\n","plt.show()\n","\n","\n","# plot the accuracy\n","plt.plot(r.history['accuracy'], label='train acc')\n","plt.plot(r.history['val_accuracy'], label='val acc')\n","plt.legend()\n","#save before show\n","plt.savefig('./train_val_acc_128.jpg')\n","plt.show()\n","\n","\n","#load best weights\n","# The model weights (that are considered the best) are loaded into the model.\n","#model.load_weights(checkpoint_filepath)\n","model.save(checkpoint_filepath)\n","#See predictions: For each image, we get probabilities for every predicted_class\n","# y_pred = model.predict(test_set)\n","# #we need to choose the predicted_class with the highest prob\n","# y_pred = np.argmax(y_pred, axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-22T08:55:17.957044Z","iopub.status.idle":"2022-02-22T08:55:17.957371Z","shell.execute_reply":"2022-02-22T08:55:17.95723Z","shell.execute_reply.started":"2022-02-22T08:55:17.957194Z"},"trusted":true},"outputs":[],"source":["# from tensorflow._api.v2.compat.v1 import ConfigProto\n","# from tensorflow._api.v2.compat.v1 import InteractiveSession\n","\n","# config = ConfigProto()\n","# config.gpu_options.per_process_gpu_memory_fraction = 0.97\n","# config.gpu_options.allow_growth = True\n","# session = InteractiveSession(config=config)\n","# from keras.callbacks import ModelCheckpoint\n","# from keras.layers import Dense, Flatten\n","# from keras.models import Model, Sequential, load_model\n","# from keras.applications.vgg import VGG16\n","# from keras.preprocessing.image import ImageDataGenerator\n","# import numpy as np\n","# from matplotlib import pyplot as plt\n","# # from utils import *\n","# import os\n","# # Import the InceptionV3  \n","# # USE imagenet weights for Transfer Learning\n","# weight_path2 = '../input/keras-efficientnetb3-no-top-weights/efficientnetb3_notop.h5'\n","# # inception = InceptionV3(input_shape=IMAGE_SIZE + [3],weights = weight_path, include_top=False)\n","# efficientNetB3 = EfficientNetB3(input_shape=IMAGE_SIZE + [3],weights = weight_path2, include_top=False)\n","# # we don't train existing weights. \n","# # We only train the last layer that will predict the predicted_classes\n","# for layer in efficientNetB3.layers:\n","#     layer.trainable = False\n","\n","# # Add preprocessing layer to the head of efficientNetB3\n","# #We use softmax because we have 15 predicted_classes\n","# x = Flatten()(efficientNetB3.output)\n","# prediction = Dense(15, activation='softmax')(x)\n","\n","# # create a model object\n","# model = Model(inputs=efficientNetB3.input, outputs=prediction)\n","# # Specify which cost func and optimization method to use\n","# model.compile(\n","#   loss='categorical_crossentropy',\n","#   optimizer='adam',\n","#   metrics=['accuracy']\n","# )\n","\n","# # Use the Image Data Generator to process images (data aug) on the fly\n","# train_datagen = ImageDataGenerator(rescale = 1./255,\n","#                                    shear_range = 0.2,\n","#                                    zoom_range = 0.2,\n","#                                    horizontal_flip = True)\n","\n","# test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","# #Specify the new size of the images and batch size\n","# training_set = train_datagen.flow_from_directory(train_path,\n","#                                                  target_size = (224, 224),\n","#                                                  batch_size = 32,\n","#                                                  class_mode = 'categorical')\n","# test_set = test_datagen.flow_from_directory(valid_path,\n","#                                             target_size = (224, 224),\n","#                                             batch_size = 32,\n","#                                             class_mode = 'categorical')\n","\n","# #set up the callback to save best model's weights\n","# checkpoint_filepath = 'EfficientNetB3.h5'\n","# model_checkpoint_callback = ModelCheckpoint(\n","#     filepath=checkpoint_filepath,\n","#     save_weights_only=False,\n","#     monitor='val_acc',\n","#     mode='max',\n","#     save_best_only=True)\n","# # fit the model\n","# # load the model\n","# # if os.path.exists(checkpoint_filepath):\n","# #   model = load_model(checkpoint_filepath)\n","# r = model.fit_generator(\n","#   training_set,\n","#   validation_data=test_set,\n","#   epochs=50,\n","#   steps_per_epoch=len(training_set),\n","#   validation_steps=len(test_set), \n","#   callbacks=[model_checkpoint_callback]\n","# )\n","\n","# # plot the loss\n","# plt.plot(r.history['loss'], label='train loss')\n","# plt.plot(r.history['val_loss'], label='val loss')\n","# plt.legend()\n","# plt.savefig('./train_val_loss2.jpg')\n","# plt.show()\n","\n","\n","# # plot the accuracy\n","# plt.plot(r.history['accuracy'], label='train acc')\n","# plt.plot(r.history['val_accuracy'], label='val acc')\n","# plt.legend()\n","# #save before show\n","# plt.savefig('./train_val_acc2.jpg')\n","# plt.show()\n","\n","\n","# #load best weights\n","# # The model weights (that are considered the best) are loaded into the model.\n","# #model.load_weights(checkpoint_filepath)\n","# model.save(checkpoint_filepath)\n","# #See predictions: For each image, we get probabilities for every predicted_class\n","# # y_pred = model.predict(test_set)\n","# # #we need to choose the predicted_class with the highest prob\n","# # y_pred = np.argmax(y_pred, axis=1)\n"]}],"metadata":{"interpreter":{"hash":"9ec22e5716d6b3a8875c213e3bd6d001645199f4bac79e779b5e79c0e3d5448e"},"kernelspec":{"display_name":"Python 3.8.12 64-bit ('fast': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":4}
